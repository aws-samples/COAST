AWSTemplateFormatVersion: 2010-09-09

Parameters:
  CurReportName:
    Type: String
    Description: |
      Optional: Name of existing Cost and Usage (CUR) report to be utilized by COAST.  
      This CUR report should be configurated as parquet with a granularity of HOURLY.
    Default: "optional_change_if_report_exists"
  DashboardUrlList:
    Type: String
    Default: '["https://raw.githubusercontent.com/aws-samples/COAST/main/grafana_dashboards/persona_dashboards/finops/finops_dashboard_v1.json","https://raw.githubusercontent.com/aws-samples/COAST/main/grafana_dashboards/persona_dashboards/executive/executive_dashboard_v1.json","https://raw.githubusercontent.com/aws-samples/COAST/main/grafana_dashboards/persona_dashboards/executive/executive_dashboard_v1.json","https://raw.githubusercontent.com/aws-samples/COAST/main/grafana_dashboards/auto_scaling/auto_scaling_dashboard_v1.json"]'
    Description: URL of COAST Executive Dashboard to be imported. See https://github.com/aws-samples/COAST/blob/main/README.md for dashboard overviews.
  ReportingEnabled:
    Type: String
    Default: "yes"
    AllowedValues:
     - "yes"
     - "no"
    Description: Allow us to collect basic usage metrics about this deployment.

Conditions:
  isReportingEnabled: !Equals [!Ref ReportingEnabled, "yes"]

Resources:
  SendStatsCustomResource:
    Type: AWS::CloudFormation::CustomResource
    Properties:   
      ServiceToken: !GetAtt SendReportingStatsFunction.Arn
      accountId: !Sub ${AWS::AccountId}
      awsRegion: !Sub ${AWS::Region}
  SendReportingStatsFunction:
    Type: AWS::Lambda::Function
    Condition: isReportingEnabled
    Properties:
      Environment:
        Variables:
          REPORTING_URL: https://emb3ni9c4k.execute-api.us-east-2.amazonaws.com/prod/coast-cfn-tracker
      Handler: index.handler
      Runtime: python3.8
      Role: !GetAtt CURStatusLambdaRole.Arn
      ReservedConcurrentExecutions: 1
      Tags:
        - Key: "deployment"
          Value: "coast"
      Code: 
       ZipFile: |
        import boto3, json, urllib3, os
        import cfnresponse
        def handler(event, context):
          responseData = {}
          cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData)  
          if event['RequestType'] == "Create":
            try:
              cf_data_json = json.dumps(event['ResourceProperties'])
              http = urllib3.PoolManager()
              response = http.request("POST", os.environ['REPORTING_URL'], headers={'Content-Type': 'application/json'}, body=cf_data_json)
              if response.status != 200:
                print(f"Received response status: {response.status}")
            except Exception as e:
              print(e)
            return
  CURStatusLambdaRole: #CUR Status Lambda Role
    Type: 'AWS::IAM::Role'
    Properties:
      RoleName:
        !Join
          - ''
          - - 'coast-lambda-status-function-'
            - !Ref AWS::StackName
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - 'sts:AssumeRole'
      Tags:
        - Key: "deployment"
          Value: "coast"

      Path: /
      Policies:
        - PolicyName: AWSS3CURLambdaExecutor
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - 'logs:CreateLogGroup'
                  - 'logs:CreateLogStream'
                  - 'logs:PutLogEvents'
                Resource: !Sub 'arn:${AWS::Partition}:logs:*:*:*'
              - Effect: Allow
                Action:
                  - 'cur:DescribeReportDefinitions'
                Resource: 
                  - '*'

  CURStatusLambda: #CUR Status Lambda
    Type: AWS::Lambda::Function
    Properties:
      FunctionName:
        !Join
          - ''
          - - 'coast-cur-status-'
            - !Ref AWS::StackName
      Code:
        ZipFile: |
          import json
          import boto3
          import logging
          import hashlib
          from datetime import datetime
          import cfnresponse

          # Configure the logging module
          logger = logging.getLogger()
          logger.setLevel(logging.DEBUG)
          
          def generate_6_digit_hash():
            # Get the current date and time as a string
            current_datetime_str = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

            # Create an MD5 hash object
            md5_hash = hashlib.md5()

            # Update the hash object with the current date and time string
            md5_hash.update(current_datetime_str.encode('utf-8'))

            # Get the hexadecimal digest of the hash
            hex_digest = md5_hash.hexdigest()

            # Take the first 6 characters of the hex digest
            six_digit_hash = hex_digest[:6]

            return six_digit_hash
          
          
          def lambda_handler(event, context):
              logger.info('Event: {}'.format(json.dumps(event)))

              try:
                provided_report = event['ResourceProperties']['ProvidedReport']
                default_report = event['ResourceProperties']['DefaultReport']
                default_output_bucket = event['ResourceProperties']['DefaultOutputBucket']
              except:
                logger.error(f'Event are not provided correctly: {event}')
                cfnresponse.send(event,context,cfnresponse.FAILED,cur_report_json)
              
              client = boto3.client('cur')

              reports = client.describe_report_definitions()
              
              cur_report = {'validated': False, 'time_unit': None, 'format': None, 'report_name': None, 'output_bucket': None, 'hash': generate_6_digit_hash() } 
              if isinstance(reports, dict) and 'ReportDefinitions' in reports:
                  for report in reports['ReportDefinitions']:
                      
                      try:
                        if report['ReportName'] == provided_report:
                            cur_report['validated'] = True
                            cur_report['report_name'] = report['ReportName']
                            cur_report['time_unit'] = report['TimeUnit']
                            cur_report['format'] = report['Format']
                            cur_report['output_bucket'] = report['S3Bucket']
                            cur_report['output_prefix'] = report['S3Prefix'].strip('/')
                            cur_report['region'] = report['S3Region']
                            cur_report['AdditionalSchemaElements'] = report['AdditionalSchemaElements']
                            break
                      except:
                        logger.error(f'Error in report: {report}')
                        cfnresponse.send(event,context,cfnresponse.FAILED,cur_report_json)
                          
                  if cur_report['time_unit'] == 'HOURLY' and cur_report['format'] == 'Parquet':
                  
                      if  isinstance(cur_report['AdditionalSchemaElements'], list):
                          if 'RESOURCES' in cur_report['AdditionalSchemaElements']:
                              cur_report['validated'] = True
                  
                  if not cur_report['validated']:
                      cur_report['report_name'] = default_report
                      cur_report['output_bucket'] = f'{default_output_bucket}-{generate_6_digit_hash()}'
                      cur_report['output_prefix'] = 'report'
                  
              logger.info(f'CUR Report Complete: {cur_report}')
              cfnresponse.send(event,context,cfnresponse.SUCCESS,cur_report)
      Role: !GetAtt CURStatusLambdaRole.Arn
      Handler: 'index.lambda_handler'
      Timeout: 30
      Runtime: python3.11
      ReservedConcurrentExecutions: 1
      Tags:
        - Key: "deployment"
          Value: "coast"

  CURStatus: #Execute CUR Status Lambda Custom Resource
    Type: 'Custom::DetermineCURStatus'
    Properties:
      ServiceToken: !GetAtt CURStatusLambda.Arn
      ProvidedReport: !Ref CurReportName
      DefaultReport:
        !Join
          - ''
          - - 'coast-cur-report-'
            - !Ref AWS::StackName
      DefaultOutputBucket: 
        !Join
          - ''
          - - 'coast-cur-bucket-'
            - !Ref AWS::StackName
      
  CURDataBucket: #CUR S3 Bucket
    Type: AWS::S3::Bucket
    DeletionPolicy: Retain
    UpdateReplacePolicy: Retain
    Properties:
      BucketName: 
        !Join
          - ''
          - - 'coast-cur-bucket-'
            - !Ref AWS::StackName
            - '-'
            - !GetAtt "CURStatus.hash"
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: AES256
      AccessControl: BucketOwnerFullControl
      OwnershipControls:
        Rules:
          - ObjectOwnership: BucketOwnerEnforced
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      VersioningConfiguration:
        Status: Enabled
      LifecycleConfiguration:
        Rules:
          - Id: Object&Version Expiration
            Status: Enabled
            NoncurrentVersionExpirationInDays: 32 
      Tags:
        - Key: "deployment"
          Value: "coast"
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: 'W35'
            reason: "Data buckets would generate too much logs"

  CURDataBucketPolicy: #CUR S3 Bucket Policy
    Type: 'AWS::S3::BucketPolicy'
    DeletionPolicy: Retain
    UpdateReplacePolicy: Delete
    Properties:
      Bucket: !Ref CURDataBucket
      PolicyDocument:
        Id: CrossAccessPolicy
        Version: "2012-10-17"
        Statement:
          - Sid: AllowTLS12Only
            Effect: Deny
            Principal: "*"
            Action: s3:*
            Resource:
              - Fn::Sub: 'arn:${AWS::Partition}:s3:::${CURDataBucket}'
              - Fn::Sub: 'arn:${AWS::Partition}:s3:::${CURDataBucket}/*'
            Condition:
              NumericLessThan:
                s3:TlsVersion: 1.2
          - Sid: AllowOnlyHTTPS
            Effect: Deny
            Principal: "*"
            Action: s3:*
            Resource:
              - Fn::Sub: 'arn:${AWS::Partition}:s3:::${CURDataBucket}'
              - Fn::Sub: 'arn:${AWS::Partition}:s3:::${CURDataBucket}/*'
            Condition:
              Bool:
                aws:SecureTransport: false
          - Sid: AllowReadBilling
            Effect: Allow
            Principal:
              Service: billingreports.amazonaws.com
            Action:
              - s3:GetBucketAcl
              - s3:GetBucketPolicy
            Resource:
              - Fn::Sub: 'arn:${AWS::Partition}:s3:::${CURDataBucket}'
              - Fn::Sub: 'arn:${AWS::Partition}:s3:::${CURDataBucket}/*'
          - Sid: AllowWriteBilling
            Effect: Allow
            Principal:
              Service: billingreports.amazonaws.com
            Action:
              - s3:PutObject
            Resource:
              - Fn::Sub: 'arn:${AWS::Partition}:s3:::${CURDataBucket}/*'
          - Sid: AllowReplicationWrite
            Effect: Allow
            Principal:
              AWS: !Ref AWS::AccountId
            Action:
              - s3:ReplicateDelete
              - s3:ReplicateObject
            Resource:
              - Fn::Sub: 'arn:${AWS::Partition}:s3:::${CURDataBucket}/*'
          - Sid: AllowReplicationRead
            Effect: Allow
            Principal:
              AWS: !Ref AWS::AccountId
            Action:
              - s3:ListBucket
              - s3:ListBucketVersions
              - s3:GetBucketVersioning
              - s3:PutBucketVersioning
            Resource:
              - Fn::Sub: 'arn:${AWS::Partition}:s3:::${CURDataBucket}'
  
  CURReport: #Create CUR report
    DependsOn:
      - CURStatus
      - CURDataBucket
      - CURDataBucketPolicy
    Type: AWS::CUR::ReportDefinition
    Properties:
      AdditionalArtifacts: 
        - ATHENA
      AdditionalSchemaElements: 
        - RESOURCES
      Compression: Parquet
      Format: Parquet
      RefreshClosedReports: True
      ReportName: 
        !Join
          - ''
          - - 'coast-cur-report-'
            - !Ref AWS::StackName
      ReportVersioning: OVERWRITE_REPORT
      S3Bucket: 
        !Join
          - ''
          - - 'coast-cur-bucket-'
            - !Ref AWS::StackName
            - '-'
            - !GetAtt "CURStatus.hash"
      S3Prefix: report
      S3Region: !Ref AWS::Region
      TimeUnit: HOURLY
  
  AWSCURDatabase: #Glue Database
    Type: 'AWS::Glue::Database'
    Properties:
      DatabaseInput:
        Name: !Join
          - ''
          - - 'coast-cur-report-'
            - !Ref AWS::StackName
      CatalogId: !Ref AWS::AccountId

  SNSNotificationsTopic: #SNS Notification for Grafana
    Type: 'AWS::SNS::Topic'

  AWSCURCrawlerRole: #Glue Crawler Role
    Type: 'AWS::IAM::Role'
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - glue.amazonaws.com
            Action:
              - 'sts:AssumeRole'
      Path: /
      Tags:
        - Key: "deployment"
          Value: "coast"
      ManagedPolicyArns:
        - !Sub 'arn:${AWS::Partition}:iam::aws:policy/service-role/AWSGlueServiceRole'
      Policies:
        - PolicyName: AWSCURCrawlerRole
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - 'logs:CreateLogGroup'
                  - 'logs:CreateLogStream'
                  - 'logs:PutLogEvents'
                Resource: !Sub 'arn:${AWS::Partition}:logs:*:*:*'
              - Effect: Allow
                Action:
                  - 'glue:UpdateDatabase'
                  - 'glue:UpdatePartition'
                  - 'glue:CreateTable'
                  - 'glue:UpdateTable'
                  - 'glue:ImportCatalogToGlue'
                Resource:
                  - !Sub 'arn:aws:glue:${AWS::Region}:${AWS::AccountId}:catalog'
                  - !Sub 'arn:aws:glue:${AWS::Region}:${AWS::AccountId}:database/${AWSCURDatabase}'
                  - !Sub 'arn:aws:glue:${AWS::Region}:${AWS::AccountId}:table/${AWSCURDatabase}/*'
              - Effect: Allow
                Action:
                  - 's3:GetObject'
                  - 's3:PutObject'
                Resource: !Sub 'arn:${AWS::Partition}:s3:::${CURStatus.output_bucket}/${CURStatus.output_prefix}/${CURStatus.report_name}/${CURStatus.report_name}*'
        - PolicyName: AWSCURKMSDecryption
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - 'kms:Decrypt'
                Resource: '*'

  AWSCURCrawler: #Glue Crawler for CUR S3 Bucket
    Type: 'AWS::Glue::Crawler'
    DependsOn:
      - AWSCURDatabase
      - AWSCURCrawlerRole
    Properties:
      Name: !Sub AWSCURCrawler-${AWS::StackName}
      Description: A recurring crawler that keeps your CUR table in Athena up-to-date.
      Role: !GetAtt AWSCURCrawlerRole.Arn
      DatabaseName: !Ref AWSCURDatabase
      Tags:
        "deployment": "coast"
      Targets:
        S3Targets:
          - Path: !Sub 's3://${CURStatus.output_bucket}/${CURStatus.output_prefix}/${CURStatus.report_name}/${CURStatus.report_name}'
            Exclusions:
              - '**.json'
              - '**.yml'
              - '**.sql'
              - '**.csv'
              - '**.gz'
              - '**.zip'
      SchemaChangePolicy:
        UpdateBehavior: UPDATE_IN_DATABASE
        DeleteBehavior: DELETE_FROM_DATABASE
    
  AWSCURInitializerRole: #Glue Crawler Lambda Role
    Type: 'AWS::IAM::Role'
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - 'sts:AssumeRole'
      Path: /
      Tags:
        - Key: "deployment"
          Value: "coast"
      Policies:
        - PolicyName: AWSCURInitializerRole
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - 'logs:CreateLogGroup'
                  - 'logs:CreateLogStream'
                  - 'logs:PutLogEvents'
                Resource: !Sub 'arn:${AWS::Partition}:logs:*:*:*'
              - Effect: Allow
                Action:
                  - 'glue:StartCrawler'
                Resource: !Sub 'arn:aws:glue:${AWS::Region}:${AWS::AccountId}:crawler/${AWSCURCrawler}'
              - Effect: Allow
                Action:
                  - 'sns:Publish'
                Resource: !Ref SNSNotificationsTopic
          
  AWSCURInitializerLambda: #Run initial crawler
    Type: 'AWS::Lambda::Function'
    DependsOn: AWSCURCrawler
    Properties:
      FunctionName:
        !Join
          - ''
          - - 'coast-cur-initializer-'
            - !Ref AWS::StackName
      Code:
        ZipFile: !Sub >
          const AWS = require('aws-sdk');
          const response = require('./cfn-response');
          exports.handler = function(event, context, callback) {
            if (event.RequestType === 'Delete') {
              response.send(event, context, response.SUCCESS);
            } else {
              const glue = new AWS.Glue();
              glue.startCrawler({ Name: '${AWSCURCrawler}' }, function(err, data) {
                if (err) {
                  const responseData = JSON.parse(this.httpResponse.body);
                  if (responseData['__type'] == 'CrawlerRunningException') {
                    callback(null, responseData.Message);
                  } else {
                    const responseString = JSON.stringify(responseData);
                    if (event.ResponseURL) {
                      response.send(event, context, response.FAILED,{ msg: responseString });
                    } else {
                      callback(responseString);
                    }
                  }
                }
                else {
                  if (event.ResponseURL) {
                    response.send(event, context, response.SUCCESS);
                  } else {
                    callback(null, response.SUCCESS);
                  }
                }
              });
            }
          };
      Handler: 'index.handler'
      Timeout: 30
      Tags:
        - Key: "deployment"
          Value: "coast"
      Runtime: nodejs16.x
      ReservedConcurrentExecutions: 1
      Role: !GetAtt AWSCURInitializerRole.Arn
     
  AWSCURInitializer: #Execute Crawler Lambda Customer Resource
    Type: 'Custom::AWSCURInitializer'
    Properties:
      ServiceToken: !GetAtt AWSCURInitializerLambda.Arn
     
  AWSS3CUREventLambdaPermission: #Allow S3 to invoke lambda on event
    Type: AWS::Lambda::Permission
    Properties:
      Action: 'lambda:InvokeFunction'
      FunctionName: !GetAtt AWSCURInitializerLambda.Arn
      Principal: 's3.amazonaws.com'
      SourceAccount: !Ref AWS::AccountId
      SourceArn: !Sub 'arn:${AWS::Partition}:s3:::${CURStatus.output_bucket}'
     
  AWSS3NotificationRole: #Role for Lambeda put event notification
    Type: 'AWS::IAM::Role'
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - 'sts:AssumeRole'
      Path: /
      Tags:
        - Key: "deployment"
          Value: "coast"
      Policies:
        - PolicyName: AWSS3NotificationRole
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - 'logs:CreateLogGroup'
                  - 'logs:CreateLogStream'
                  - 'logs:PutLogEvents'
                Resource: !Sub 'arn:${AWS::Partition}:logs:*:*:*'
              - Effect: Allow
                Action:
                  - 's3:PutBucketNotification'
                Resource: !Sub 'arn:${AWS::Partition}:s3:::${CURStatus.output_bucket}'
       
  AWSS3NotificationLambda: #Put S3 event notification to bucket
    Type: 'AWS::Lambda::Function'
    DependsOn:
    - AWSCURInitializerLambda
    - AWSS3CUREventLambdaPermission
    - AWSS3NotificationRole
    - CURStatus
    Properties:
      Code:
        ZipFile: >
          const AWS = require('aws-sdk');
          const response = require('./cfn-response');
          exports.handler = function(event, context, callback) {
            const s3 = new AWS.S3();
            const putConfigRequest = function(notificationConfiguration) {
              return new Promise(function(resolve, reject) {
                s3.putBucketNotificationConfiguration({
                  Bucket: event.ResourceProperties.BucketName,
                  NotificationConfiguration: notificationConfiguration
                }, function(err, data) {
                  if (err) reject({ msg: this.httpResponse.body.toString(), error: err, data: data });
                  else resolve(data);
                });
              });
            };
            const newNotificationConfig = {};
            if (event.RequestType !== 'Delete') {
              newNotificationConfig.LambdaFunctionConfigurations = [{
                Events: [ 's3:ObjectCreated:*' ],
                LambdaFunctionArn: event.ResourceProperties.TargetLambdaArn || 'missing arn',
                Filter: { Key: { FilterRules: [ { Name: 'prefix', Value: event.ResourceProperties.ReportKey } ] } }
              }];
            }
            putConfigRequest(newNotificationConfig).then(function(result) {
              response.send(event, context, response.SUCCESS, result);
              callback(null, result);
            }).catch(function(error) {
              response.send(event, context, response.FAILED, error);
              console.log(error);
              callback(error);
            });
          };
      Handler: 'index.handler'
      Timeout: 30
      Runtime: nodejs16.x
      Tags:
        - Key: "deployment"
          Value: "coast"
      ReservedConcurrentExecutions: 1
      Role: !GetAtt AWSS3NotificationRole.Arn

  AWSS3Notification: #Execute S3 notification custom resource
    Type: 'Custom::AWSS3Notification'
    Properties:
      ServiceToken: !GetAtt AWSS3NotificationLambda.Arn
      TargetLambdaArn: !GetAtt AWSCURInitializerLambda.Arn
      BucketName: !Sub '${CURStatus.output_bucket}'
      ReportKey: !Sub '${CURStatus.output_prefix}/${CURStatus.report_name}/${CURStatus.report_name}'

  GlueCURReportStatusTable: #Create cur status table in glue/athena
    Type: 'AWS::Glue::Table'
    DependsOn: 
      - AWSCURDatabase
      - CURStatus
    Properties:
      DatabaseName: !Ref AWSCURDatabase
      CatalogId: !Ref AWS::AccountId
      TableInput:
        Name: 'cost_and_usage_data_status'
        TableType: 'EXTERNAL_TABLE'
        StorageDescriptor:
          Columns:
            - Name: status
              Type: 'string'
          InputFormat: 'org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat'
          OutputFormat: 'org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat'
          SerdeInfo:
            SerializationLibrary: 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'
          Location: !Sub 's3://${CURStatus.output_bucket}/${CURStatus.output_prefix}/${CURStatus.report_name}/cost_and_usage_data_status/'

  AthenaQueryResultsBucket: #Create S3 bucket fork workgroup query results
    Type: AWS::S3::Bucket
    DeletionPolicy: Retain
    Properties:
      BucketName: 
        !Join
          - ''
          - - 'coast-athena-query-results-'
            - !Ref AWS::StackName
            - '-'
            - !GetAtt "CURStatus.hash"            
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: AES256
      AccessControl: BucketOwnerFullControl
      OwnershipControls:
        Rules:
          - ObjectOwnership: BucketOwnerEnforced
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      LifecycleConfiguration:
        Rules:
          - Id: DeleteContent
            Status: 'Enabled'
            ExpirationInDays: 7
      VersioningConfiguration:
        Status: Enabled
      Tags:
        - Key: "deployment"
          Value: "coast"

  AthenaWorkGroup:  #Create athena workgroup 
    Type: AWS::Athena::WorkGroup
    DependsOn:
      - AthenaQueryResultsBucket
    Properties:
      Name: 
        !Join
          - ''
          - - 'coast-workgroup-'
            - !Ref AWS::StackName
      Description: 'Used for COAST'
      RecursiveDeleteOption: true
      Tags:
        - Key: "GrafanaDataSource"
          Value: "false"
        - Key: "deployment"
          Value: "coast"
      WorkGroupConfiguration:
        EnforceWorkGroupConfiguration: true
        PublishCloudWatchMetricsEnabled: true
        ResultConfiguration:
          EncryptionConfiguration:
            EncryptionOption: SSE_S3
          OutputLocation: !Sub 's3://${AthenaQueryResultsBucket}'
          AclConfiguration:
            S3AclOption: BUCKET_OWNER_FULL_CONTROL
      Tags:
        - Key: GrafanaDataSource
          Value: 'true'

  GrafanaWorkspaceRole: #Role for Grafana workspace
    Type: AWS::IAM::Role
    Properties: 
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
        - Effect: Allow
          Principal:
            Service: 'grafana.amazonaws.com'
          Action: 'sts:AssumeRole'
      Description: 'COAST Grafana Workspace Role'
      Tags:
        - Key: "deployment"
          Value: "coast"
      ManagedPolicyArns: 
        - 'arn:aws:iam::aws:policy/service-role/AmazonGrafanaAthenaAccess'
        - 'arn:aws:iam::aws:policy/service-role/AmazonGrafanaCloudWatchAccess'
      Policies:
        - PolicyName: 'GrafanaAthenaS3Access'
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
                Effect: Allow
                Action:
                  - 's3:GetBucketLocation'
                  - 's3:GetObject'
                  - 's3:ListBucket'
                  - 's3:ListBucketMultipartUploads'
                  - 's3:ListMultipartUploadParts'
                  - 's3:AbortMultipartUpload'
                  - 's3:CreateBucket'
                  - 's3:PutObject'
                  - 's3:PutBucketPublicAccessBlock'
                Resource:
                  - !Sub 'arn:aws:s3:::${CURStatus.output_bucket}'
                  - !Sub 'arn:aws:s3:::${CURStatus.output_bucket}/*'
                  - !Sub 'arn:aws:s3:::${AthenaQueryResultsBucket}'
                  - !Sub 'arn:aws:s3:::${AthenaQueryResultsBucket}/*'
      Path: /

  GrafanaWorkspace: #Create Grafana workspace
    Type: AWS::Grafana::Workspace
    Properties: 
      AccountAccessType: CURRENT_ACCOUNT
      AuthenticationProviders: 
        - AWS_SSO
      DataSources: 
        - CLOUDWATCH
        - ATHENA
      Description: 'COAST Project Workspace'
      GrafanaVersion: '9.4'
      PluginAdminEnabled: true
      Name:
        !Join
          - ''
          - - 'COAST-'
            - !Ref AWS::StackName
      NotificationDestinations: 
        - SNS
      PermissionType: SERVICE_MANAGED
      RoleArn: !Ref GrafanaWorkspaceRole

  GrafanaLambdaFunctionRole: #Role required for Grafana Datasource and CoastDashboard functions
    Type: AWS::IAM::Role
    Properties:
      RoleName:
        !Join
          - ''
          - - 'coast-grafana-lambda-role'
            - !Ref AWS::StackName
      AssumeRolePolicyDocument:
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - 'sts:AssumeRole'
      Path: /
      Tags:
        - Key: "deployment"
          Value: "coast"
      Policies:
        - PolicyName: 'coast-datasource-lambda'
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - 'logs:CreateLogGroup'
                  - 'logs:CreateLogStream'
                  - 'logs:PutLogEvents'
                Resource: !Sub 'arn:${AWS::Partition}:logs:*:*:*'
              - Effect: Allow
                Action:
                  - 'sns:Publish'
                Resource: !Ref SNSNotificationsTopic
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AWSGrafanaAccountAdministrator

  GrafanaDataSourceFunction: #Lambda function to create Grafana data source
    Type: AWS::Lambda::Function
    Properties:
      Code:
        ZipFile: |
          import cfnresponse
          import boto3
          import urllib3
          import json
          import logging

          # Configure the logging module
          logger = logging.getLogger()
          logger.setLevel(logging.DEBUG)

          SUCCESS="SUCCESS"
          FAILED="FAILED"
          class CoastGrafanaWorkspace:
              client=boto3.client('grafana')
              http=urllib3.PoolManager()
              def __init__(self,athena_db,athena_region,athena_workgroup,datasource_name,key_name,workspace_id,plugin_list):
                  self.logger = logging.getLogger()
                  self.logger.setLevel(logging.DEBUG)
                  self.athena_db=athena_db
                  self.athena_region=athena_region
                  self.athena_workgroup=athena_workgroup
                  self.datasource_name=datasource_name
                  self.plugin_list=plugin_list
                  self.datasource_uid_list = []
                  self.workspace=self.get_workspace(workspace_id)
                  self.key=self.create_key(key_name)
                  self.common_headers={'Accept':'application/json','Content-Type':'application/json','Authorization':'Bearer '+self.key['key']}
              def get_workspace(self,workspace_id):
                  '''return a the workspace id or return None'''
                  workspaces=self.client.list_workspaces()
                  
                  for workspace in workspaces['workspaces']:
                      if workspace['id']==workspace_id:
                          return workspace

                  return None

              def create_key(self,key_name):
                  '''delete grafana api key and create new key'''
                  try:
                      self.client.delete_workspace_api_key(keyName=key_name,workspaceId=self.workspace['id'])
                  except client.exceptions.ResourceNotFoundException as rnfe:
                      self.logger.info(f'Unable to delete key.  This is not a breaking error.: {rnfe}.')
                  except Exception as err:
                      print('Error:'+str(err))
                      pass
                  finally:
                      return self.client.create_workspace_api_key(keyName=key_name,keyRole='ADMIN',secondsToLive=60,workspaceId=self.workspace['id'])
              
              def install_plugin(self,plugin) -> None:
                  '''install plugin, currently only required for Athena'''
                  if plugin == 'athena':
                    body = {}
                    
                    install_athena = self.grafana_api('POST','plugins/grafana-athena-datasource/install',bytes(json.dumps(body),encoding='utf-8'))

                    self.logger.info(f'Install Athena plugin status: {install_athena.status}')
                    #self.logger.info(f'Install Athena Data: {install_athena.data}')

                    return None
              
              def delete_datasource(self):
                  '''delete datasource, required for CFN template termination'''
                  success = True #this variable will be used in the future
                  result = self.grafana_api('GET','datasources')
                  
                  if result.status == 200:
                      datasources = json.loads(result.data)
                  else:
                      success = False
                    
                  # Find the ID of the datasource by name
                  datasource_uid = None
                  for datasource in datasources:
                      #I harded coded CW here, I don't expect to have many more datasources
                      #if we do in the future we should make this more dynamic
                      if datasource['name'] == self.datasource_name or datasource['name'] == 'Cloudwatch':
                          datasource_uid = datasource['uid']
                
                          delete_plugin = self.grafana_api('DELETE',f'datasources/uid/{datasource_uid}')

                          if delete_plugin.status != 200:
                            success = False
                            self.logger.info(f"Error deleting datasource: {delete_plugin.json()}")
                            return success

                  return success
              
              def set_datasource_body(self, plugin, body=''):
                  '''return body needed for creation of datasource'''
                  
                  if plugin == 'athena':
                    body = {'name':self.datasource_name,'type':'grafana-athena-datasource','access':'proxy','url':'','user':'','database':'','basicAuth':False,'isDefault':False,'jsonData':{'authType':'ec2_iam_role','catalog':'AwsDataCatalog','database':self.athena_db,'defaultRegion':self.athena_region,'provisionedBy':'COAST','workgroup':self.athena_workgroup},'readOnly':False}
                  if plugin == 'cloudwatch':
                    body = {'access': 'proxy', 'isDefault': True, 'name': 'Cloudwatch', 'type': plugin}
              
                  return bytes(json.dumps(body),encoding='utf-8')

              def create_datasource(self):
                  success = True
                  for plugin in self.plugin_list:
                    #install plugin, only required for non-core plugins
                    self.install_plugin(plugin)

                    enable_plugin = self.grafana_api('POST','datasources',self.set_datasource_body(plugin))

                    self.logger.info(f'Enable {plugin} plugin status: {enable_plugin.status}')

                    if enable_plugin.status != 200:
                      success = False
                    
                  return success
              
              def grafana_api(self,method,path,body=None):
                  url='https://'+self.workspace['endpoint']+'/api/'+path
                  headers={'Accept':'application/json','Content-Type':'application/json','Authorization':'Bearer '+self.key['key']}
                  print(method + ' ' + url + ' ' + str(body))
                  
                  res=self.http.request(method,url,headers=headers,body=body)
                  
                  return res

          def lambda_handler(event,context):
              print(json.dumps(event,indent=4))
              response_data={'Data': None}
              plugin_list=['athena', 'cloudwatch']
              try:
                  id=event['PhysicalResourceId'] if 'PhysicalResourceId' in event else '0'
                  ws=CoastGrafanaWorkspace(athena_db=event['ResourceProperties']['AthenaDB'],athena_region=event['ResourceProperties']['AthenaRegion'],athena_workgroup=event['ResourceProperties']['AthenaWorkgroup'],datasource_name=event['ResourceProperties']['DataSource'],key_name=event['ResourceProperties']['GrafanaKey'],workspace_id=event['ResourceProperties']['GrafanaWorkspace'],plugin_list=plugin_list)
                  
                  if event['RequestType']=='Create':
                      result=ws.create_datasource()
                                            
                      if result:
                          cfnresponse.send(event,context,cfnresponse.SUCCESS,response_data)
                      else:
                          cfnresponse.send(event,context,cfnresponse.FAILED,response_data)
                  elif event['RequestType']=='Delete':
                      result=ws.delete_datasource()
                      
                      if result:
                          logger.info('Successfully deleted datasources')
                          cfnresponse.send(event,context,cfnresponse.SUCCESS,response_data)
                      else:
                          logger.info('Failed to delete datasources')
                          cfnresponse.send(event,context,cfnresponse.FAILED,response_data)

              except Exception as err:
                  print('Error:'+str(err))
                  cfnresponse.send(event,context,cfnresponse.FAILED,response_data,'0')

      FunctionName:
        !Join
          - ''
          - - 'coast-grafana-datasource-'
            - !Ref AWS::StackName
      Role: !GetAtt GrafanaLambdaFunctionRole.Arn
      Handler: 'index.lambda_handler'
      Timeout: 30

      Tags:
        - Key: "deployment"
          Value: "coast"
      Runtime: python3.10
      ReservedConcurrentExecutions: 1

  GrafanaDatasource: #Execute lambda data source creation; custom resource
    Type: 'Custom::GrafanaDatasource'
    DependsOn:
      - GrafanaWorkspace
    Properties:
      ServiceToken: !GetAtt GrafanaDataSourceFunction.Arn
      AthenaDB: 
        !Join
          - ''
          - - 'coast-cur-report-'
            - !Ref AWS::StackName
      AthenaRegion: !Ref AWS::Region
      AthenaWorkgroup: !Ref AthenaWorkGroup
      DataSource: 'COAST-2023-09-19' #Do not change until we update our templates
      GrafanaKey: !Ref AWS::StackName
      GrafanaWorkspace: !Ref GrafanaWorkspace
      CoastWorkspace: !GetAtt "GrafanaWorkspace.Name"

  COASTDashboardFunction: #Lambda function to import COAST Dashboard
    Type: AWS::Lambda::Function
    Properties:
      Code:
        ZipFile: |
          import cfnresponse
          import boto3
          import urllib3
          import json
          SUCCESS="SUCCESS"
          FAILED="FAILED"
          class CoastGrafanaDashboard:
              client=boto3.client('grafana')
              http=urllib3.PoolManager()
              def __init__(self,dashboard_name,dashboard_url,key_name,workspace_id):
                  self.dashboard_name=dashboard_name
                  self.dashboard_url=dashboard_url
                  self.workspace=self.get_workspace(workspace_id)
                  self.key=self.create_key(key_name)
                  self.common_headers={'Accept':'application/json','Content-Type':'application/json','Authorization':'Bearer '+self.key['key']}
              def get_workspace(self,workspace_id):
                  workspaces=self.client.list_workspaces()
                  for workspace in workspaces['workspaces']:
                      if workspace['id']==workspace_id:
                          return workspace
              def create_key(self,key_name):
                  try:
                      self.client.delete_workspace_api_key(keyName=key_name,workspaceId=self.workspace['id'])
                  except Exception as err:
                      print('Error:'+str(err))
                      pass
                  finally:
                      return self.client.create_workspace_api_key(keyName=key_name,keyRole='ADMIN',secondsToLive=60,workspaceId=self.workspace['id'])
              def grafana_api(self,method,path,body=None):
                  url='https://'+self.workspace['endpoint']+'/api/'+path
                  print(method+' '+url)
                  return self.http.request(method,url,headers=self.common_headers,body=body)
              def set_dashboard_body(self):
                  body={}
                  body['dashboard']=json.loads(self.http.request('GET',self.dashboard_url).data)
                  body['dashboard']['id']=None
                  body['overwrite']=True
                  return bytes(json.dumps(body),encoding='utf-8')
              def create_dashboard(self):
                  return self.grafana_api('POST','dashboards/db',self.set_dashboard_body())
              def delete_dashboard(self,uid):
                  return self.grafana_api('DELETE','dashboards/uid/'+uid)
          def lambda_handler(event,context):
              print(json.dumps(event,indent=4))
              params =event['ResourceProperties']['DashboardUrlList']
              lst = json.loads(params)
              response_data={'Data': None}
              try:
                  for dashboardUrl in lst:
                    uid=event['PhysicalResourceId'] if 'PhysicalResourceId' in event else '0'
                    ws=CoastGrafanaDashboard(dashboard_name=event['ResourceProperties']['DashboardName'],dashboard_url=str(dashboardUrl),key_name=event['ResourceProperties']['GrafanaKey'],workspace_id=event['ResourceProperties']['GrafanaWorkspace'])
                    if event['RequestType']=='Create':
                        res=ws.create_dashboard()
                    elif event['RequestType']=='Update':
                        ws.delete_dashboard(uid)
                        res=ws.create_dashboard()
                    elif event['RequestType']=='Delete':
                        res=ws.delete_dashboard(uid)
                        cfnresponse.send(event,context,cfnresponse.SUCCESS,response_data)
                    print('Status: '+str(res.status))
                    print(res.data)
                    if 'uid' in json.loads(res.data):
                       dashboard_uid=str(json.loads(res.data)['uid']) 
                    else:
                        dashboard_uid='0'
                    if res.status==200 or (event['RequestType']=='Delete' and uid=='0'):
                        cfnresponse.send(event,context,cfnresponse.SUCCESS,response_data,dashboard_uid)
                    else:
                        cfnresponse.send(event,context,cfnresponse.FAILED,response_data,dashboard_uid)
              except Exception as err:
                  print('Error:'+str(err))
                  cfnresponse.send(event,context,cfnresponse.FAILED,response_data,'0')
      FunctionName:
        !Join
          - ''
          - - 'coast-dashboard-function-'
            - !Ref AWS::StackName
      Role: !GetAtt GrafanaLambdaFunctionRole.Arn
      Handler: 'index.lambda_handler'
      Timeout: 30
      Tags:
        - Key: "deployment"
          Value: "coast"
      Runtime: python3.10
      ReservedConcurrentExecutions: 1

  COASTDashboard: #Execute lambda function to import COAST Dashboard; custom resource
    Type: 'Custom::GrafanaDashboard'
    DependsOn:
      - GrafanaDatasource
    Properties:
      ServiceToken: !GetAtt COASTDashboardFunction.Arn
      DashboardName: !Sub 'COAST-${AWS::StackName}'
      DashboardUrlList: !Ref DashboardUrlList
      DashboardDatasource: !Ref GrafanaDatasource
      GrafanaKey: !Ref AWS::StackName
      GrafanaWorkspace: !Ref GrafanaWorkspace

Outputs:
  CurReportStatus:
    Description: If you have provided a CUR report in the parameters, COAST ran logic to validate if the report is in the necessary format.  This value will be true if COAST used an existing CUR report.
    Value: !GetAtt "CURStatus.validated"
  
  GrafanaWorkspace:
    Description: The Grafana workspace associated with this stack.
    Value: !GetAtt "GrafanaWorkspace.Name"  

  CurReportName:
    Description: This is the CUR report either created or used by the stack.
    Value: !GetAtt "CURStatus.report_name"

  CurBucketName:
    Description: This is the CUR bucket created or used by this stack.
    Value: !GetAtt "CURStatus.output_bucket"
